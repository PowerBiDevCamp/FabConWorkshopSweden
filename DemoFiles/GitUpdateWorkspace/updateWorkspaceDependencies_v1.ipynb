{"cells":[{"cell_type":"code","source":["#default parameters\n","default_lakehouse = \"wwilakehouse\" \n","workspace_id = \"XX\"\n","lakehouse_id = \"XX\"\n","notebook_names = \"01 - Create Delta Tables,02 - Data Transformation - Business Aggregates\"\n"],"outputs":[],"execution_count":null,"metadata":{"tags":["parameters"],"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fb7c38a1-4956-4a63-afc0-40ed37330218"},{"cell_type":"code","source":["!pip -q install semantic-link-labs"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"47a94e80-4ecf-42ea-b3b5-d25c970a07ea"},{"cell_type":"code","source":["import json\n","import sempy_labs as labs\n","from sempy_labs import migration, directlake\n","from sempy_labs import lakehouse as lake\n","from sempy_labs import report as rep\n","from sempy_labs.tom import connect_semantic_model\n","from notebookutils import notebook"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ff8b53c9-ee2a-435e-bc45-7d5727295090"},{"cell_type":"code","source":["def update_notebooks_default_lakehouse(notebooks, new_default_lakehouse_id):\n","    for notebook_name in notebooks:\n","        # Get the current notebook definition\n","        notebook_def = notebookutils.notebook.getDefinition(notebook_name)\n","        json_payload = json.loads(notebook_def)\n","        \n","        # Check and remove any attached lakehouses\n","        if 'dependencies' in json_payload['metadata'] and 'lakehouse' in json_payload['metadata']['dependencies']:\n","        # Remove all lakehouses\n","            json_payload['metadata']['dependencies']['lakehouse'] = {}\n","\n","            #Update new notebook definition after removing existing lakehouses and with new default lakehouseId\n","            (notebookutils.notebook.updateDefinition(\n","                        name = notebook_name,\n","                        content  = json.dumps(json_payload),  \n","                        defaultLakehouse = default_lakehouse,\n","                        defaultLakehouseWorkspace = workspace_id\n","                        )\n","                )\n","        print(f\"Updated notebook {notebook_name} with new default lakehouse: {default_lakehouse} in {workspace_id}\")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e0cff2ea-6208-4d53-a7b6-fe323e9cecb6"},{"cell_type":"code","source":["\"\"\"\n","https://semantic-link-labs.readthedocs.io/en/stable/sempy_labs.html#sempy_labs.resolve_lakehouse_id\n","\n","Workspace is defaulted to notebook when not passed explicity and notebook is not attached to any lakehouse\n","\"\"\"\n","\n","#default_lakehouse_id = labs.resolve_lakehouse_id(default_lakehouse)\n","#print(default_lakehouse_id)\n","\n","#Rebind notebooks to default lakehouse of the current workspaces and remove dependecies from previous workspace\n","lst_Notebook = notebook_names.split(',')\n","update_notebooks_default_lakehouse(lst_Notebook,lakehouse_id)\n","\n","print(\"Rebind notebooks to default lakehouse of the current workspaces and remove dependecies from previous workspace \")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bbfb7502-5a44-470e-9146-2ff8f4b0ba08"},{"cell_type":"code","source":["#Run the notebooks to rehydrate the lakehouse and load the data\n","for notebook_name in lst_Notebook:\n","    notebookutils.notebook.run(notebook_name)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"944260fb-ee9d-4c0a-a378-e4dd0ecbf7d2"},{"cell_type":"code","source":["    labs.directlake.update_direct_lake_model_lakehouse_connection(\"WWI-DirectLakeModel\", lakehouse = \"wwilakehouse\")\n","    #https://semantic-link-labs.readthedocs.io/en/stable/sempy_labs.directlake.html#sempy_labs.directlake.update_direct_lake_model_lakehouse_connection\n","    \n","    labs.report.report_rebind(\"WWIReport\", \"WWI-DirectLakeModel\")\n","    \n","    #labs.refresh_semantic_model(\"WWI-DirectLakeModel\")\n","    #https://semantic-link-labs.readthedocs.io/en/stable/sempy_labs.html#sempy_labs.refresh_semantic_model"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6ea67b33-b99f-412b-a069-e54ac9ab0aa3"},{"cell_type":"code","source":["\"\"\"\n","lst_of_notebooks = notebookutils.notebook.list()\n","\n","changed_notebook_id = []\n","\n","for notebook_object in lst_of_notebooks:\n","    if (notebook_object['displayName'] in lst_Notebook ):\n","        changed_notebook_id.append(notebook_object['id'])\n","\n","print (changed_notebook_id)            \n","labs.commit_to_git(\"Committing Notebook after rebinding process\")#,\"4b16dc2-4c30-4cba-9c38-c619d9acfdcc\",\"frnuson_main_dev_workspace\")\n","\n","\"\"\""],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2eed15d9-1e46-4e5e-b9c3-613badb9ad68"}],"metadata":{"language_info":{"name":"python"},"kernel_info":{"name":"synapse_pyspark"},"a365ComputeOptions":null,"sessionKeepAliveTimeout":0,"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"widgets":{},"nteract":{"version":"nteract-front-end@1.0.0"},"spark_compute":{"compute_id":"/trident/default"},"dependencies":{"lakehouse":{"default_lakehouse":null,"default_lakehouse_name":"","default_lakehouse_workspace_id":""},"environment":{}}},"nbformat":4,"nbformat_minor":5}